# ğŸ“§ DetecÃ§Ã£o de Phishing em Emails

Este projeto implementa um modelo de **detecÃ§Ã£o de phishing em emails**, utilizando tÃ©cnicas de **Processamento de Linguagem Natural (NLP)** e aprendizado de mÃ¡quina leve, para permitir incorporaÃ§Ã£o em ferramentas de uso direto pelo usuÃ¡rio, como extensÃµes de navegador.

---

## ğŸ¯ DefiniÃ§Ã£o do Problema

O objetivo deste projeto Ã© **avaliar e identificar emails de phishing** de forma automÃ¡tica, utilizando apenas o texto contido no corpo do email.

**Premissas e hipÃ³teses:**
- Emails de phishing podem ser detectados analisando o conteÃºdo textual.
- Modelos leves sÃ£o suficientes para fornecer uma primeira linha de defesa ao usuÃ¡rio.
- A traduÃ§Ã£o para inglÃªs permite que um Ãºnico modelo generalize para mÃºltiplos idiomas.

**CondiÃ§Ãµes de seleÃ§Ã£o de dados:**
- Apenas o texto do email e a classificaÃ§Ã£o (phishing/legÃ­timo) foram utilizados.
- Arquivos anexos nÃ£o sÃ£o analisados.
- A escolha de analisar apenas o texto foi feita para garantir **simplicidade, baixo custo computacional e rapidez**.  
  âš ï¸ Entretanto, outros metadados, como remetente ou links, podem ser Ãºteis. Por exemplo:
  - Um remetente como `mercadolivre@gmail.com` provavelmente Ã© um phishing, simulando um domÃ­nio legÃ­timo.
  - Um link como `mercadolivre.vendasrapidas.com` tambÃ©m indica tentativa de simular um site legÃ­timo.

**DescriÃ§Ã£o do dataset:**
- Dataset inicial: tabela CSV com duas colunas:
  - `Email Text`: texto do email
  - `Email Type`: classificaÃ§Ã£o (`Safe Email` ou `Phishing Email`)
- A classificaÃ§Ã£o alvo Ã© **Phishing Email**.
- LimitaÃ§Ã£o do TF-IDF: o modelo aprende apenas o vocabulÃ¡rio presente no dataset. Isso pode reduzir generalizaÃ§Ã£o caso o dataset seja muito especÃ­fico.

---

## ğŸ“Š AnÃ¡lise ExploratÃ³ria

### 1. DistribuiÃ§Ã£o de classes
- Emails seguros (`Safe Email`): 60%
- Emails de phishing (`Phishing Email`): 40%
- Existe um **desbalanceamento moderado**, mas condizente com a realidade, onde a maioria dos emails sÃ£o seguros.

### 2. DistribuiÃ§Ã£o do tamanho dos emails
- Calculado o nÃºmero de caracteres de cada email.
- VisualizaÃ§Ãµes mostram que emails de phishing podem ter tamanhos variados, permitindo identificar **padrÃµes relevantes para o modelo**.

âœ… Resumo:
- Balanceamento de classes aceitÃ¡vel.
- Tamanho dos emails influencia a escolha das features de texto (TF-IDF e n-grams).

---

## âš™ï¸ PrÃ©-processamento e VetorizaÃ§Ã£o

1. **Limpeza do texto**
   - ConversÃ£o para minÃºsculas.
   - RemoÃ§Ã£o de quebras de linha e mÃºltiplos espaÃ§os.
   - RemoÃ§Ã£o de pontuaÃ§Ã£o e caracteres especiais.

2. **TF-IDF**
   - Converte cada email em vetor numÃ©rico baseado na importÃ¢ncia das palavras.
   - Considera **unigramas e bigramas**.
   - Limita o vocabulÃ¡rio (`max_features=500`) para manter simplicidade e baixo consumo de memÃ³ria.

3. **SeparaÃ§Ã£o treino/teste**
   - 80% treino, 20% teste.

4. **LazyClassifier**
   - Treina e avalia diversos modelos automaticamente.
   - Permite comparar algoritmos de forma rÃ¡pida e cientÃ­fica.

---

## ğŸ“ˆ AvaliaÃ§Ã£o com Recall da Classe Positiva

- Em detecÃ§Ã£o de phishing, **falsos negativos** (emails maliciosos nÃ£o detectados) sÃ£o crÃ­ticos.
- **Recall da classe positiva** mede a capacidade de identificar corretamente emails de phishing.
- O modelo escolhido foi o que apresentou **maior Recall e menor tempo de execuÃ§Ã£o** entre os modelos testados.

**Nota:** o "tempo" exibido pelo LazyClassifier indica **quanto demorou para treinar e avaliar cada modelo** nos dados de teste.

---

## ğŸ§ª AvaliaÃ§Ã£o em Datasets Adicionais

Para testar a **capacidade de generalizaÃ§Ã£o**, o modelo foi avaliado em datasets diferentes:

- Segundo dataset: emails distintos do dataset inicial, testando generalizaÃ§Ã£o.
- Terceiro dataset: proveniente de outra fonte, com colunas `Category` (legÃ­timo/phishing) e `Message`.

âš ï¸ ObservaÃ§Ã£o: os resultados mostraram que o modelo **perde desempenho em datasets muito distintos**, indicando possÃ­vel **overfitting**.

### EstratÃ©gia de mÃºltiplos datasets
- Para reduzir overfitting, Ã© possÃ­vel juntar **5 datasets distintos**, dividir cada um em 80% treino e 20% teste, e treinar um modelo Ãºnico.
- Isso aumenta a **abrangÃªncia do vocabulÃ¡rio** e melhora a generalizaÃ§Ã£o.

---

## ğŸŒ PrediÃ§Ã£o em MÃºltiplos Idiomas

- O modelo foi treinado em **emails em inglÃªs**.
- Para suportar outros idiomas, os textos sÃ£o **traduzidos automaticamente para inglÃªs** usando `deep_translator` (identifica o idioma original automaticamente).
- Essa abordagem permite que um **Ãºnico modelo funcione para mÃºltiplos idiomas**, sem necessidade de treinar modelos separados.

**Exemplo de idiomas testados:**
- ğŸ‡ºğŸ‡¸ InglÃªs
- ğŸ‡µğŸ‡¹ PortuguÃªs
- ğŸ‡«ğŸ‡· FrancÃªs

âœ… ObservaÃ§Ã£o:
- O modelo identifica corretamente phishing independentemente do idioma.
- A **probabilidade de pertencer Ã  classe positiva** varia por idioma, mostrando o impacto da traduÃ§Ã£o.

---

## ğŸ”¹ Pipeline de ClassificaÃ§Ã£o

- Pipeline: `TF-IDF + LGBMClassifier` jÃ¡ treinado.
- FunÃ§Ã£o `traduz_e_classifica`:
  1. TraduÃ§Ã£o do texto para inglÃªs.
  2. ClassificaÃ§Ã£o pelo pipeline.
  3. Retorna prediÃ§Ã£o e probabilidade de phishing.

- FunÃ§Ã£o `predict(user_text)`:
  - Recebe texto do usuÃ¡rio.
  - Retorna resultado de phishing/safe e probabilidade.

---

## âœ… ConclusÃ£o

- O modelo leve com TF-IDF + LGBM mostrou **bom desempenho** no dataset original.
- Em datasets distintos, houve queda de desempenho, indicando **necessidade de maior diversidade de dados para treino**.
- Uso de traduÃ§Ã£o permite **aplicaÃ§Ã£o em mÃºltiplos idiomas**.
- A abordagem Ã© simples, rÃ¡pida e adequada para incorporaÃ§Ã£o em ferramentas de uso direto pelo usuÃ¡rio.
