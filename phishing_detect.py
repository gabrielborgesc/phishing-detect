# -*- coding: utf-8 -*-
"""Phishing Detect.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lqHikaU5ZVmwHI7eFEkby5Ewa3z1Tt8o

# üìù Defini√ß√£o do Problema

## üéØ Objetivo
O objetivo deste trabalho √© desenvolver um **modelo de detec√ß√£o de phishing** leve, eficiente e capaz de ser integrado em ferramentas de aux√≠lio ao usu√°rio, como **extens√µes de navegador**. A proposta √© criar uma solu√ß√£o **simples, de baixo custo computacional**, mas com desempenho satisfat√≥rio para identificar emails phishing de forma confi√°vel.

---

## üîç Descri√ß√£o do Problema
O problema consiste em **classificar emails como phishing ou leg√≠timos** a partir do seu conte√∫do textual. Emails phishing geralmente tentam enganar o usu√°rio para obter informa√ß√µes sens√≠veis ou induzi-lo a executar a√ß√µes maliciosas. Detectar esses emails de forma autom√°tica ajuda a reduzir riscos de seguran√ßa.

---

## üí° Premissas e Hip√≥teses
- **Premissa:** Emails podem ser diferenciados como phishing ou n√£o a partir de seu texto, sem necessidade de metadados adicionais, embora os metadados tamb√©m possam ser √∫teis.
- **Hip√≥tese:** Um modelo baseado em **TF-IDF** para extra√ß√£o de caracter√≠sticas e um classificador leve (como LGBM) consegue atingir um bom equil√≠brio entre **desempenho** e **baixo custo computacional**.
- Embora existam modelos mais robustos baseados em **Transformers**, eles n√£o foram considerados devido ao **alto custo de processamento**, incompat√≠vel com o objetivo de um modelo embutido em ferramentas simples.

---

## ‚ö†Ô∏è Restri√ß√µes e Condi√ß√µes de Sele√ß√£o dos Dados

- Nesta implementa√ß√£o, foi utilizada **apenas a an√°lise do texto do e-mail** (corpo da mensagem) como entrada do modelo.  
  Essa escolha foi proposital, com o objetivo de manter o foco em **conte√∫do textual** e avaliar o desempenho do modelo exclusivamente com base nas palavras utilizadas.  

- No entanto, em um cen√°rio mais amplo, outros **metadados** do e-mail podem contribuir significativamente para a detec√ß√£o de phishing, como:
  - **Remetente:** endere√ßos suspeitos como `mercadolivre@gmail.com` podem indicar tentativas de se passar por empresas leg√≠timas que normalmente utilizam dom√≠nios corporativos.  
  - **Links contidos no corpo do e-mail:** URLs como `mercadolivre.vendasrapidas.com` podem tentar **simular sites oficiais** para enganar o usu√°rio.  
  A an√°lise desses elementos ‚Äî combinada com o conte√∫do textual ‚Äî tende a **aumentar a robustez do modelo** em aplica√ß√µes reais.

- A abordagem **TF-IDF** transforma o texto em vetores num√©ricos baseados na **frequ√™ncia das palavras** dentro do dataset utilizado para treino.  
  Isso significa que o modelo aprende a import√¢ncia relativa de cada palavra apenas a partir dos dados dispon√≠veis.  

  ‚ö†Ô∏è **Limita√ß√£o:** se o dataset tiver um **vocabul√°rio restrito** ou focar em um contexto muito espec√≠fico, o modelo s√≥ conhecer√° esse conjunto limitado de palavras.  
  Como resultado, ele pode **n√£o generalizar bem** para e-mails com termos ou express√µes diferentes, mesmo que tamb√©m sejam phishing.  

- Esse √© um **trade-off**: ganha-se simplicidade e baixo custo computacional, mas pode-se perder parte da capacidade de generaliza√ß√£o.  
  Portanto, √© importante utilizar um dataset **abrangente e diversificado**, que represente diferentes contextos de e-mails reais o m√°ximo poss√≠vel.


---

## üóÇÔ∏è Descri√ß√£o do Dataset
- Url Kaggle: https://www.kaggle.com/datasets/subhajournal/phishingemails
- Url Planilha utilizada pelo notebook: https://docs.google.com/spreadsheets/d/1pQu1m_W_-cyQ6Xu2Ogak31YCuJvHrbZlOSz3PRRXLVE/export?format=csv&sheet=phishing_email
- **Formato:** CSV
- **Colunas:**
  - `Email Text`: corpo do email (string)
  - `Email Type`: classifica√ß√£o (`Safe Email` ou `Phishing Email`)
- **Classe alvo:** `Phishing Email` (1), `Safe Email` (0)
- **Quantidade de registros:** 18.651, com distribui√ß√£o 60% (safe) / 40% (phishing).

# Instala√ß√£o de pacotes
"""

!pip install -q scikit-learn pandas numpy matplotlib seaborn gdown
!pip install lazypredict
!pip install -q transformers sentencepiece langdetect
!pip install deep-translator

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import re

from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, roc_auc_score, precision_recall_curve, auc, confusion_matrix, recall_score
from lazypredict.Supervised import LazyClassifier
from sklearn.model_selection import train_test_split
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import classification_report, roc_auc_score, average_precision_score
from lightgbm import LGBMClassifier
from sklearn.model_selection import cross_val_score, StratifiedKFold
from sklearn.metrics import ConfusionMatrixDisplay
import matplotlib.pyplot as plt
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import recall_score
import pandas as pd
from sklearn.pipeline import Pipeline
from deep_translator import GoogleTranslator

"""### üì• Carregamento e prepara√ß√£o inicial do dataset

Neste trecho, estamos carregando os dados de emails a partir de um arquivo CSV hospedado no **Google Sheets**, o qual foi exportado do Kaggle (https://www.kaggle.com/datasets/subhajournal/phishingemails), e preparando-os para an√°lise e treinamento do modelo.

"""

url = "https://docs.google.com/spreadsheets/d/1pQu1m_W_-cyQ6Xu2Ogak31YCuJvHrbZlOSz3PRRXLVE/export?format=csv&sheet=phishing_email"

df = pd.read_csv(url)

# Mapear classes para 0/1
df['label'] = df['Email Type'].map({'Safe Email': 0, 'Phishing Email': 1})

df.head(), df.info()

"""### üìä An√°lise explorat√≥ria: distribui√ß√£o de classes e tamanho dos emails

Antes de treinar o modelo, √© importante entender **como os dados est√£o distribu√≠dos**.

1. **Distribui√ß√£o de classes**  
   - Verificamos o n√∫mero de emails de cada classe (`Safe Email` e `Phishing Email`) e tamb√©m a propor√ß√£o de cada uma em rela√ß√£o ao total.  
   - Isso permite identificar se h√° **desbalanceamento de classes**, ou seja, se existem muito mais emails leg√≠timos do que phishing.  
   - Entender o balanceamento ajuda a escolher estrat√©gias de treino e m√©tricas apropriadas para avalia√ß√£o do modelo.

2. **Distribui√ß√£o do tamanho dos emails**  
   - Calculamos o **n√∫mero de caracteres de cada email** para entender a varia√ß√£o no tamanho dos textos.  
   - A an√°lise visual mostra se emails de phishing tendem a ser mais curtos ou mais longos que os emails leg√≠timos, permitindo identificar **padr√µes importantes para o modelo**.  
   - Escalas logar√≠tmicas s√£o √∫teis quando existem diferen√ßas grandes na quantidade de emails de determinados tamanhos.

‚úÖ **Resumo:**  
Com essa an√°lise inicial, conseguimos insights sobre:
- O **balanceamento das classes**, que impacta diretamente na performance do modelo.  
- O **tamanho t√≠pico dos emails**, que pode influenciar a escolha de features de texto, como TF-IDF e n-grams.  

üìà **Resultado observado:**  
A an√°lise mostrou que cerca de **60% dos emails s√£o seguros (Safe Email)** e **40% s√£o phishing**.  
Embora exista um leve **desbalanceamento de classes**, ele √© **aceit√°vel** e **reflete bem a realidade**, j√° que, em contextos reais, a maioria dos emails tende a ser leg√≠tima.  
Esse equil√≠brio moderado permite que o modelo aprenda bem os dois tipos de mensagens, sem precisar de t√©cnicas complexas de balanceamento.

"""

print("Distribui√ß√£o de classes:")
print(df['label'].value_counts())
print("\nPropor√ß√£o de phishing vs leg√≠timo:")
print(df['label'].value_counts(normalize=True))

df['length'] = df['Email Text'].fillna('').apply(len)
sns.histplot(data=df, x='length', hue='label', bins=50, log_scale=True)
plt.title("Distribui√ß√£o de quantidade de caracteres dos e-mails por classe")
plt.show()

"""### üßπ Pr√©-processamento dos textos

Nesta etapa, √© realizada a **limpeza e padroniza√ß√£o** do conte√∫do textual dos e-mails para preparar os dados para o modelo de aprendizado de m√°quina.  
O processo envolve v√°rias transforma√ß√µes no texto original, com o objetivo de reduzir ru√≠dos e garantir que o algoritmo trabalhe apenas com informa√ß√µes relevantes.

#### ‚úèÔ∏è Etapas do pr√©-processamento

1. **Convers√£o para letras min√∫sculas:**  
   Todos os caracteres s√£o transformados em min√∫sculos para evitar distin√ß√µes desnecess√°rias entre palavras como ‚ÄúEmail‚Äù e ‚Äúemail‚Äù.

2. **Remo√ß√£o de quebras de linha e espa√ßos extras:**  
   Quebras de linha (`\n`) e m√∫ltiplos espa√ßos consecutivos s√£o substitu√≠dos por um √∫nico espa√ßo, garantindo um texto mais limpo e uniforme.

3. **Remo√ß√£o de pontua√ß√£o e s√≠mbolos irrelevantes:**  
   S√£o mantidos apenas **letras, n√∫meros e espa√ßos**. Caracteres especiais (como `@`, `#`, `!`, `?`, etc.) s√£o removidos para eliminar ru√≠dos que n√£o agregam valor ao modelo baseado em palavras.

4. **Tratamento de valores nulos:**  
   Caso algum e-mail esteja vazio, ele √© substitu√≠do por uma string vazia, evitando erros no processamento.

#### üéØ Resultado

Ap√≥s essa etapa, o dataset passa a conter uma nova coluna (`text`) com os e-mails **limpos, padronizados e prontos para serem vetorizados** pelo m√©todo **TF-IDF**, usado posteriormente na extra√ß√£o de caracter√≠sticas textuais.

"""

def preprocess_text(text):
    text = str(text).lower()
    # Remove quebras de linha e m√∫ltiplos espa√ßos
    text = text.replace('\n', ' ')
    text = ' '.join(text.split())
    # Remove pontua√ß√£o extra, mantendo palavras e n√∫meros
    text = re.sub(r'[^a-z0-9\s]', '', text)
    return text

# Aplicar ao dataframe
df['text'] = df['Email Text'].fillna('').apply(preprocess_text)

"""## ‚öôÔ∏è Vetoriza√ß√£o com TF-IDF e Avalia√ß√£o Autom√°tica de Modelos

Ap√≥s o pr√©-processamento do texto, √© necess√°rio **converter as palavras em n√∫meros** para que os algoritmos de aprendizado de m√°quina consigam processar os dados.  
Nesta etapa, √© utilizado o **TF-IDF (Term Frequency ‚Äì Inverse Document Frequency)**, uma t√©cnica cl√°ssica e eficiente para representa√ß√£o textual.

---

### üß† **1. Separa√ß√£o das vari√°veis**
- `X` ‚Üí cont√©m os textos pr√©-processados.  
- `y` ‚Üí cont√©m os r√≥tulos num√©ricos (`0` para *Safe Email* e `1` para *Phishing Email*).  

---

### üßÆ **2. Transforma√ß√£o em vetores num√©ricos**
√â utilizado o `TfidfVectorizer`, que:
- Converte cada e-mail em um vetor de n√∫meros, refletindo a **import√¢ncia relativa de cada palavra** no conjunto de dados.  
- Considera **unigramas e bigramas** (`ngram_range=(1,2)`), ou seja, palavras individuais e pares de palavras consecutivas.
- Limita o vocabul√°rio a **500 termos mais relevantes** (`max_features=500`), equilibrando desempenho e consumo de mem√≥ria.

Essa etapa gera uma **matriz esparsa**, onde cada linha representa um e-mail e cada coluna representa uma palavra ou par de palavras.

---

### üíæ **3. Convers√£o para matriz densa**
O `LazyClassifier` ‚Äî biblioteca utilizada para testar rapidamente v√°rios modelos ‚Äî requer que os dados estejam em formato **denso**.  
Assim, o comando:
```python
X_dense = X_tfidf.toarray()
```

### ü§ñ **4. Avalia√ß√£o autom√°tica de modelos**

Nesta etapa, utilizamos o `LazyClassifier` ‚Äî uma ferramenta que permite **avaliar automaticamente diversos algoritmos de aprendizado de m√°quina** aplicados ao mesmo conjunto de dados.  
O objetivo √© conduzir uma **compara√ß√£o emp√≠rica e cient√≠fica** entre diferentes modelos, observando m√©tricas como **Acur√°cia, F1-Score, ROC AUC**, entre outras.

Essa metodologia possibilita identificar **qual algoritmo apresenta melhor desempenho** para o cen√°rio em quest√£o, sem precisar treinar manualmente cada modelo.

Al√©m disso, o `LazyClassifier` oferece um ranking final, ordenando os modelos de acordo com suas m√©tricas de performance.  
Dessa forma, o processo de escolha do modelo mais adequado torna-se **objetivo, reprodut√≠vel e fundamentado em resultados quantitativos**.

"""

X = df['text']
y = df['label']

# TF-IDF (limitar max_features para n√£o estourar mem√≥ria)
tfidf = TfidfVectorizer(max_features=500, ngram_range=(1,2))
X_tfidf = tfidf.fit_transform(X)

# Converter para dense array, necess√°rio para LazyClassifier
X_dense = X_tfidf.toarray()

# Separa√ß√£o treino/teste
X_train, X_test, y_train, y_test = train_test_split(
    X_dense, y, stratify=y, test_size=0.2, random_state=42
)

# Cria o LazyClassifier
clf = LazyClassifier(predictions=True)

# Treina e avalia v√°rios modelos automaticamente
models, predictions = clf.fit(X_train, X_test, y_train, y_test)

# Exibe ranking dos modelos (por padr√£o sorted por Accuracy)
print(models)

"""## üìä Avalia√ß√£o Focada na Classe Positiva (Phishing)

Ap√≥s a execu√ß√£o do `LazyClassifier`, obt√©m-se uma tabela com m√©tricas gerais de desempenho de v√°rios algoritmos.  
No entanto, em problemas de **detec√ß√£o de phishing**, √© importante dar **√™nfase √† classe positiva (1 = Phishing Email)** ‚Äî j√° que falsos negativos (phishings n√£o detectados) s√£o muito mais cr√≠ticos do que falsos positivos.

---

### üéØ **1. C√°lculo do Recall da classe positiva**
O **Recall**, neste caso, mede a capacidade do modelo de **identificar corretamente os e-mails de phishing**.  

Ou seja, quanto maior o *Recall*, menor a chance de o modelo deixar passar um e-mail malicioso.

No c√≥digo, √© criado um dicion√°rio (`recalls`) que armazena o *Recall* da classe positiva (`pos_label=1`) para cada modelo avaliado.

---

### üìà **2. Inclus√£o do Recall na tabela de resultados**
O valor do *Recall* √© adicionado √† tabela original de modelos (`models`), gerando um novo *DataFrame* (`models_with_recall`) com uma coluna adicional chamada **‚ÄúRecall‚Äù**.

---

### üîΩ **3. Ordena√ß√£o por desempenho em Recall**
Por fim, a tabela √© reordenada de forma decrescente pelo *Recall*, com:
```python
sort_values(by='Recall', ascending=False)
```

---

### üß† **4. Escolha do modelo ideal**
Com base na tabela ordenada, o modelo selecionado foi aquele que **apresentou o maior valor de *Recall*** (ou seja, melhor capacidade de detectar e-mails de phishing) **e o menor tempo de execu√ß√£o**.  

Neste caso, espec√≠fico, foi o modelo `LGBMClassifier`.

Essa escolha prioriza a **efici√™ncia na detec√ß√£o de amea√ßas** sem comprometer o **desempenho computacional** ‚Äî garantindo que o sistema seja tanto **preciso** quanto **√°gil** na identifica√ß√£o de e-mails maliciosos.


"""

# Calcula Recall da classe positiva (1 = Phishing Email)
recalls = {model: recall_score(y_test, predictions[model], pos_label=1)
           for model in predictions.columns}

# Adiciona Recall √† tabela original
models_with_recall = models.join(pd.DataFrame.from_dict(recalls, orient='index', columns=['Recall']))

# Ordena pelo Recall
models_with_recall_sorted = models_with_recall.sort_values(by='Recall', ascending=False)

print(models_with_recall_sorted)

"""## üß† Prepara√ß√£o dos Dados e Extra√ß√£o de Caracter√≠sticas com TF-IDF

Esta etapa √© respons√°vel por preparar os dados para o treinamento do modelo de aprendizado de m√°quina.  
Ela envolve duas fases principais: **divis√£o dos dados** e **transforma√ß√£o textual com TF-IDF**.

---

### ‚úÇÔ∏è **1. Separa√ß√£o entre features e r√≥tulos**
Primeiro, as colunas s√£o separadas:
- `X` cont√©m o **texto dos e-mails** (`Email Text`);
- `y` cont√©m a **classifica√ß√£o alvo**, mapeada para valores num√©ricos:
  - `0` ‚Üí *Safe Email* (e-mail leg√≠timo)  
  - `1` ‚Üí *Phishing Email* (e-mail malicioso)

Essa codifica√ß√£o bin√°ria √© essencial para que o modelo possa interpretar corretamente as classes durante o treinamento.

---

### üîÄ **2. Divis√£o em conjuntos de treino e teste**
Os dados s√£o divididos em:
- **Treino (80%)** ‚Üí usado para o modelo ‚Äúaprender‚Äù padr√µes lingu√≠sticos;
- **Teste (20%)** ‚Üí usado para avaliar a capacidade do modelo de generalizar para novos dados.

O par√¢metro `stratify=y` garante que a propor√ß√£o entre e-mails leg√≠timos e de phishing seja **mantida em ambos os conjuntos**, evitando vi√©s de amostragem.

---

### üß© **3. Extra√ß√£o de caracter√≠sticas com TF-IDF**
O texto cru dos e-mails n√£o pode ser usado diretamente pelos algoritmos de machine learning.  
Por isso, √© convertido em **vetores num√©ricos** por meio da t√©cnica **TF-IDF (Term Frequency ‚Äì Inverse Document Frequency)**.

- `max_features=2000` ‚Üí limita o vocabul√°rio a **2.000 termos mais relevantes**, equilibrando desempenho e mem√≥ria.  
- `ngram_range=(1,2)` ‚Üí considera **unigramas** (palavras isoladas) e **bigramas** (pares de palavras consecutivas), permitindo capturar express√µes comuns como *"click here"* ou *"account suspended"*.

Ap√≥s o ajuste (`fit_transform`) no conjunto de treino, o mesmo vocabul√°rio √© usado para transformar o conjunto de teste (`transform`), garantindo consist√™ncia.

---

üí° **Em resumo:**  
Esta etapa converte o conte√∫do textual dos e-mails em representa√ß√µes num√©ricas otimizadas para aprendizado, preparando o terreno para o treinamento e a avalia√ß√£o de modelos de detec√ß√£o de phishing.

"""

# -------------------------
# Separar X e y
X = df['Email Text'].fillna('')
y = df['Email Type'].map({'Safe Email': 0, 'Phishing Email': 1})  # codifica 0/1

# Split treino/teste
X_train, X_test, y_train, y_test = train_test_split(
    X, y, stratify=y, test_size=0.2, random_state=42
)

# -------------------------
# TF-IDF
tfidf = TfidfVectorizer(max_features=2000, ngram_range=(1,2))
X_train_tfidf = tfidf.fit_transform(X_train)
X_test_tfidf = tfidf.transform(X_test)

"""### üîÑ Valida√ß√£o Cruzada com LGBM

Para avaliar a robustez do modelo antes de test√°-lo em dados externos, realizamos **Valida√ß√£o Cruzada Estratificada (Stratified K-Folds)** com 5 folds.  

---

#### üõ† Passos:

1. **Defini√ß√£o do modelo LGBM**  
   Configuramos um **LightGBM Classifier** com:
   - `n_estimators=500`: n√∫mero de √°rvores no ensemble.
   - `learning_rate=0.05`: taxa de aprendizado.
   - `random_state=42`: para reprodutibilidade.

2. **Cria√ß√£o dos folds estratificados**  
   Usando `StratifiedKFold`, garantimos que cada fold mant√©m a **mesma propor√ß√£o de classes** (Safe vs Phishing) do conjunto de treino.

3. **Execu√ß√£o da Valida√ß√£o Cruzada**  
   O `cross_val_score` calcula o **ROC AUC** em cada fold, fornecendo uma medida de **desempenho m√©dio do modelo** em diferentes subconjuntos dos dados.

4. **Resultados**  
   - `ROC AUC m√©dio`: indica a **capacidade geral do modelo de discriminar entre e-mails leg√≠timos e de phishing**.
   - `Desvio padr√£o entre folds`: mostra a **consist√™ncia do modelo**; valores baixos indicam que o desempenho n√£o varia muito entre diferentes divis√µes dos dados.
"""

lgbm = LGBMClassifier(
    n_estimators=500,
    learning_rate=0.05,
    random_state=42
)

# Cria folds estratificados (mant√©m propor√ß√£o entre classes)
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# Executa cross-validation
scores = cross_val_score(lgbm, X_train_tfidf, y_train, cv=cv, scoring='roc_auc')

print(f"ROC AUC m√©dio na valida√ß√£o cruzada: {np.mean(scores):.4f}")
print(f"Desvio padr√£o entre folds: {np.std(scores):.4f}")

"""### üèãÔ∏è Treinamento do LGBMClassifier

Ap√≥s a avalia√ß√£o inicial com Valida√ß√£o Cruzada, o **LightGBM Classifier** √© treinado no **conjunto de treino completo**.

---

#### üõ† Configura√ß√£o do modelo:

- `n_estimators=500`: n√∫mero de √°rvores na floresta, controlando a complexidade do ensemble.
- `learning_rate=0.05`: taxa de aprendizado, determinando o quanto cada √°rvore contribui para o modelo final.
- `random_state=42`: garante que o treinamento seja reprodut√≠vel.

---
"""

# -------------------------
# Treinar LGBMClassifier
lgbm = LGBMClassifier(
    n_estimators=500,
    learning_rate=0.05,
    random_state=42
)
lgbm.fit(X_train_tfidf, y_train)

"""### üß™ Fun√ß√£o `avaliar_modelo`

A fun√ß√£o `avaliar_modelo` permite **avaliar um modelo de classifica√ß√£o** em um conjunto de teste, gerando m√©tricas cl√°ssicas e exibindo exemplos de predi√ß√µes incorretas.

---

#### üîπ Par√¢metros:

- `modelo`: modelo treinado (pode ser pipeline ou classificador com m√©todos `predict` e `predict_proba`).
- `X_test`: dados de teste (TF-IDF, pipeline, etc.).
- `y_test`: labels correspondentes.
- `X_textos` textos originais correspondentes a `X_test`. √ötil para inspecionar erros.
- `target_names`: nomes das classes para exibi√ß√£o (`['Safe Email', 'Phishing Email']` por padr√£o).
- `titulo_matriz`: t√≠tulo para a matriz de confus√£o.
- `n_erros`: n√∫mero de exemplos de predi√ß√µes incorretas a exibir.

---

#### ‚ö° Funcionalidades:

1. **Predi√ß√£o**  
   O modelo faz predi√ß√µes sobre `X_test` com `predict` e calcula probabilidades com `predict_proba`.

2. **Relat√≥rio de classifica√ß√£o**  
   Exibe `precision`, `recall`, `f1-score` e `support` para cada classe.

3. **M√©tricas adicionais**  
   Calcula e exibe:
   - **ROC AUC**: mede a capacidade do modelo de separar classes.
   - **PR AUC**: √°rea sob a curva Precision-Recall.

4. **Matriz de Confus√£o**  
   Gera visualiza√ß√£o da matriz de confus√£o para an√°lise de acertos e erros por classe.

5. **Exemplos de predi√ß√µes incorretas** *(se `X_textos` for fornecido)*  
   Exibe os primeiros `n_erros` textos onde o modelo errou, mostrando:
   - Valor verdadeiro
   - Predi√ß√£o do modelo
   - Texto do e-mail

---

Essa fun√ß√£o √© √∫til para **an√°lise qualitativa e quantitativa do modelo**, permitindo identificar padr√µes de erro e avaliar seu desempenho em dados reais.

"""

def avaliar_modelo(modelo, X_test, y_test, X_textos=None, target_names=['Safe Email', 'Phishing Email'],
                    titulo_matriz="Matriz de Confus√£o", n_erros=5):
    """
    Avalia um modelo em um conjunto de teste.

    Par√¢metros:
    - modelo: pipeline ou modelo treinado com m√©todos predict e predict_proba
    - X_test: dados de teste (TF-IDF, pipeline, etc.)
    - y_test: labels correspondentes
    - X_textos: lista/Series com os textos originais correspondentes a X_test (opcional)
    - target_names: nomes das classes
    - titulo_matriz: t√≠tulo da matriz de confus√£o
    - n_erros: n√∫mero de exemplos de predi√ß√µes incorretas a exibir
    """

    # Predi√ß√£o
    y_pred = modelo.predict(X_test)

    # Probabilidade da classe positiva
    y_proba = modelo.predict_proba(X_test)[:, 1]

    # Relat√≥rio de classifica√ß√£o
    print("===== RELAT√ìRIO DE CLASSIFICA√á√ÉO =====\n")
    print(classification_report(y_test, y_pred, target_names=target_names))

    # M√©tricas de ROC AUC e PR AUC
    roc_auc = roc_auc_score(y_test, y_proba)
    pr_auc = average_precision_score(y_test, y_proba)

    print(f"ROC AUC: {roc_auc:.4f}")
    print(f"PR AUC: {pr_auc:.4f}")

    # Matriz de confus√£o
    cm = ConfusionMatrixDisplay.from_estimator(
        modelo,
        X_test,
        y_test,
        display_labels=target_names,
        cmap=plt.cm.Blues,
        normalize=None
    )
    plt.title(titulo_matriz)
    plt.show()

    # Exibir exemplos de predi√ß√µes incorretas
    if X_textos is not None:
        print(f"\n===== {n_erros} EXEMPLOS DE PREDI√á√ïES INCORRETAS =====\n")
        erros_idx = [i for i in range(len(y_test)) if y_test.iloc[i] != y_pred[i]] if hasattr(y_test, "iloc") else [i for i in range(len(y_test)) if y_test[i] != y_pred[i]]
        for i in erros_idx[:n_erros]:
            true_label = target_names[y_test.iloc[i]] if hasattr(y_test, "iloc") else target_names[y_test[i]]
            pred_label = target_names[y_pred[i]]
            texto = X_textos.iloc[i] if hasattr(X_textos, "iloc") else X_textos[i]
            print(f"Verdadeiro: {true_label} | Predi√ß√£o: {pred_label}\nTexto: {texto}\n{'-'*60}\n")

"""## üß™ Avalia√ß√£o do Modelo nos Dados de Teste

Para avaliar o desempenho do modelo treinado (`LGBMClassifier`) nos dados de teste, foi utilizada a fun√ß√£o `avaliar_modelo` criada acima.

Essa fun√ß√£o realiza as seguintes etapas:

1. **Predi√ß√£o e probabilidades**  
   O modelo √© utilizado para prever as classes dos e-mails de teste (`X_test_tfidf`).  
   Tamb√©m s√£o calculadas as probabilidades associadas √† classe positiva (1 = Phishing Email), que s√£o usadas para m√©tricas como ROC AUC e PR AUC.

2. **Relat√≥rio de classifica√ß√£o**  
   √â exibido um resumo com m√©tricas padr√£o (`precision`, `recall`, `f1-score`) para cada classe, permitindo analisar a performance geral do modelo.

3. **Matriz de confus√£o**  
   A matriz de confus√£o mostra visualmente a distribui√ß√£o de predi√ß√µes corretas e incorretas, destacando falsos positivos e falsos negativos.

4. **Exemplos de predi√ß√µes incorretas**  
   Passando os textos originais (`X_test`) para o par√¢metro `X_textos`, a fun√ß√£o exibe alguns casos de e-mails classificados incorretamente, mostrando:
   - O valor verdadeiro (`Safe Email` ou `Phishing Email`)  
   - A predi√ß√£o do modelo  
   - O conte√∫do do e-mail
"""

avaliar_modelo(lgbm, X_test_tfidf, y_test, X_textos=X_test)

"""## üß™ Avalia√ß√£o do Modelo em um Segundo Dataset

Ap√≥s treinar o modelo `LGBMClassifier` no primeiro dataset, foi utilizado **um outro dataset inteiramento como conjunto de teste**.  

O objetivo √© verificar se o modelo consegue **generalizar bem** para textos possivelmente de contextos diferentes daqueles presentes no dataset usado para treino.  

Embora o dataset original tenha sido dividido em treino e teste, √© importante notar que mesmo o conjunto de teste interno pode n√£o refletir totalmente a capacidade de generaliza√ß√£o do modelo, especialmente se o dataset como um todo se concentrar em textos muito espec√≠ficos.


---

### 1Ô∏è‚É£ Carregamento do segundo dataset
O dataset √© carregado a partir de um arquivo CSV hospedado no Google Sheets. Ele cont√©m duas colunas principais:  
- `Email Text`: texto completo do e-mail  
- `Email Type`: classifica√ß√£o do e-mail (`Safe Email` ou `Phishing Email`)

---

### 2Ô∏è‚É£ Pr√©-processamento
Aplicamos a mesma fun√ß√£o de pr√©-processamento (`preprocess_text`) usada no dataset original para garantir consist√™ncia:
- Convers√£o para min√∫sculas  
- Remo√ß√£o de quebras de linha e m√∫ltiplos espa√ßos  
- Limpeza de caracteres especiais

Al√©m disso, as classes s√£o mapeadas para **0 (Safe)** e **1 (Phishing)**.

---

### 3Ô∏è‚É£ Transforma√ß√£o com TF-IDF
O TF-IDF j√° treinado no primeiro dataset √© utilizado para transformar os textos do segundo dataset.  
Dessa forma, garantimos que o modelo recebe **a mesma representa√ß√£o vetorial** que foi usada no treinamento.

---

### 4Ô∏è‚É£ Avalia√ß√£o do modelo
Chamamos a fun√ß√£o `avaliar_modelo` passando:  
- `lgbm`: modelo treinado  
- `X_segundo_tfidf`: dados de teste transformados pelo TF-IDF  
- `y_segundo`: labels verdadeiros  
- `X_textos`: textos originais do segundo dataset  
- `titulo_matriz`: t√≠tulo personalizado da matriz de confus√£o

Essa avalia√ß√£o permite analisar:
- M√©tricas quantitativas (precision, recall, f1-score, ROC AUC, PR AUC)  
- Matriz de confus√£o visual  
- Exemplos de predi√ß√µes incorretas, para entender melhor onde o modelo erra

---

‚úÖ Com isso, conseguimos verificar **como o modelo generaliza para dados possivelmente em contextos diferentes**, mantendo consist√™ncia com o pr√©-processamento e a representa√ß√£o TF-IDF.

"""

# -------------------------
# 1. Carregar o 2¬∫ dataset
# -------------------------
url_segundo = "https://docs.google.com/spreadsheets/d/1FjEs_IDpphw1OUYGzsUj80hlqrsLMdXE74ZNRGCfhEU/export?format=csv"
df_segundo = pd.read_csv(url_segundo)

# -------------------------
# 2. Pr√©-processamento
# -------------------------
df_segundo['text'] = df_segundo['Email Text'].fillna('').apply(preprocess_text)
X_segundo = df_segundo['text']
y_segundo = df_segundo['Email Type'].map({'Safe Email': 0, 'Phishing Email': 1})

# -------------------------
# 3. Transformar com TF-IDF j√° treinado
# -------------------------
X_segundo_tfidf = tfidf.transform(X_segundo)

# -------------------------
# 4. Avaliar modelo no 2¬∫ dataset
# -------------------------
avaliar_modelo(lgbm, X_segundo_tfidf, y_segundo, titulo_matriz="Matriz de Confus√£o - 2¬∫ Dataset", X_textos=X_segundo)

"""## üåê Fun√ß√£o de Tradu√ß√£o e Classifica√ß√£o de E-mails Multil√≠ngue

O modelo `LGBMClassifier + TF-IDF` foi **treinado inteiramente para e-mails em ingl√™s**.  
Para permitir que ele seja utilizado em textos em outros idiomas, cada e-mail √© **traduzido para ingl√™s antes da classifica√ß√£o**.  

### üîπ Objetivo:
- Tornar **um √∫nico modelo aplic√°vel a v√°rios idiomas**, sem a necessidade de treinar modelos separados para cada idioma.
- A biblioteca consegue **identificar automaticamente o idioma de origem**, qualquer que seja ele.
- Aproveitar o car√°ter **geral dos e-mails**, que normalmente n√£o possuem vocabul√°rio excessivamente t√©cnico, permitindo que a tradu√ß√£o preserve o significado relevante para a detec√ß√£o de phishing.

### üîπ Funcionamento da fun√ß√£o `traduz_e_classifica`:
1. **Tradu√ß√£o para ingl√™s**
   - Utiliza a biblioteca `deep_translator` (`GoogleTranslator`) para traduzir o texto do idioma original para ingl√™s.
   - Se o texto j√° estiver em ingl√™s, a tradu√ß√£o n√£o altera o conte√∫do.
2. **Predi√ß√£o com pipeline TF-IDF + LGBM**
   - O texto traduzido √© processado pelo **pipeline treinado**, que combina **TF-IDF** e **LGBMClassifier**.
   - Retorna a predi√ß√£o: `Phishing` (classe positiva) ou `Safe` (classe negativa).
3. **C√°lculo da probabilidade de phishing**
   - A fun√ß√£o tamb√©m retorna a **probabilidade associada √† classe phishing**, √∫til para interpreta√ß√£o do risco.
4. **Tratamento de erros**
   - Se ocorrer qualquer problema durante a tradu√ß√£o ou predi√ß√£o, a fun√ß√£o retorna uma mensagem de erro no dicion√°rio.

### üîπ Limita√ß√µes:
- Em cen√°rios com **vocabul√°rio muito espec√≠fico** (como jarg√£o t√©cnico ou termos de setores especializados), a tradu√ß√£o pode n√£o preservar completamente o significado, podendo afetar a acur√°cia do modelo.

### üîπ Sa√≠da da fun√ß√£o:
```python
{
    'predicao': 'Phishing' ou 'Safe',
    'probabilidade_phishing': 'XX.XX%'
}
```
"""

# Cria pipeline TF-IDF + LGBM (j√° treinados)
pipeline_lgbm = Pipeline([
    ('tfidf', tfidf),
    ('clf', lgbm)
])

def traduz_e_classifica(texto, pipeline_modelo):
    """
    Traduz o texto para ingl√™s e aplica o pipeline de classifica√ß√£o.

    Retorna:
    - dicion√°rio com predi√ß√£o ('Phishing' ou 'Safe') e probabilidade de phishing
    """
    try:
        # Traduz para ingl√™s (se j√° estiver em ingl√™s, n√£o muda)
        texto_en = GoogleTranslator(source='auto', target='en').translate(texto)

        # Predi√ß√£o
        pred = pipeline_modelo.predict([texto_en])[0]

        # Probabilidade de phishing
        prob = pipeline_modelo.predict_proba([texto_en])[0][1]

        return {
            'predicao': 'Phishing' if pred == 1 else 'Safe',
            'probabilidade_phishing': f"{prob*100:.2f}%"
        }

    except Exception as e:
        return {'erro': str(e)}

"""### üîπ Cria√ß√£o do Pipeline TF-IDF + LGBM

- O **pipeline** combina duas etapas principais:
  1. **TF-IDF (`tfidf`)**: j√° treinado com o dataset original, converte os textos em vetores num√©ricos baseados na frequ√™ncia e relev√¢ncia das palavras.
  2. **LGBM (`lgbm`)**: classificador j√° treinado, respons√°vel por prever se o e-mail √© **Phishing** ou **Safe**.

- Essa abordagem permite que, ao receber um novo texto, ele seja automaticamente transformado pelo TF-IDF e classificado pelo LGBM em sequ√™ncia.
- O uso de um pipeline facilita **reaproveitar o modelo treinado** sem precisar aplicar manualmente cada etapa de pr√©-processamento.

"""

# Cria pipeline TF-IDF + LGBM
pipeline_lgbm = Pipeline([
    ('tfidf', tfidf),   # TF-IDF j√° treinado
    ('clf', lgbm)       # LGBM j√° treinado
])

"""### üîπ Fun√ß√£o `predict`

- A fun√ß√£o `predict` recebe um texto de e-mail fornecido pelo usu√°rio e realiza a **classifica√ß√£o autom√°tica**.
- Passos principais:
  1. **Chama `traduz_e_classifica`**: traduz o texto para ingl√™s (se necess√°rio) e aplica o pipeline TF-IDF + LGBM j√° treinado.
  2. **Recebe o resultado**: um dicion√°rio contendo:
     - `predicao`: `"Phishing"` ou `"Safe"`  
     - `probabilidade_phishing`: a probabilidade de ser phishing, em percentual.
  3. **Exibe o resultado** no console usando `print`.

- Essa fun√ß√£o permite testar rapidamente **qualquer e-mail** sem precisar manipular o pipeline diretamente.

"""

def predict(user_text):
  resultado = traduz_e_classifica(user_text, pipeline_lgbm)
  print(resultado)

"""### üì® Pequena Amostragem de Teste Multil√≠ngue

Para demonstrar o funcionamento do modelo, foram criadas **2 mensagens de e-mail**:

1. **E-mail seguro (Safe Email)**  
2. **E-mail de phishing (Phishing Email)**  

Cada uma delas foi disponibilizada em **tr√™s idiomas**:  
üá∫üá∏ **Ingl√™s (EUA)** ‚Äî üáßüá∑ **Portugu√™s (Brasil)** ‚Äî üá´üá∑ **Franc√™s (Fran√ßa)**

**Objetivo:**  
Verificar se o modelo, treinado exclusivamente em **dados em ingl√™s**, √© capaz de **classificar corretamente e-mails escritos em outros idiomas**.  
Para isso, utiliza-se a fun√ß√£o `predict`, que chama internamente `traduz_e_classifica`, realizando a **tradu√ß√£o autom√°tica para o ingl√™s** antes da predi√ß√£o.

**Resultados observados:**  
O modelo foi capaz de **identificar corretamente o tipo de e-mail (seguro ou phishing)** em todos os idiomas testados, demonstrando que o processo de tradu√ß√£o permite **generalizar o modelo para diferentes l√≠nguas** sem necessidade de treinar vers√µes espec√≠ficas para cada uma.  

Entretanto, observa-se que a **probabilidade associada √† classe predita varia entre os idiomas**, refletindo o **impacto da tradu√ß√£o autom√°tica** sobre o texto original.  
Essas varia√ß√µes podem ocorrer devido a **diferen√ßas sutis de vocabul√°rio e contexto** introduzidas pelo tradutor.

"""

english_safe_email = """
Hi John,

I hope you‚Äôre doing well. I just wanted to remind you about our meeting scheduled for tomorrow at 10 AM. Please let me know if you need to reschedule or if there‚Äôs anything specific you‚Äôd like to discuss.

Best regards,
Emily
"""

portuguese_safe_email = """
Ol√°, John,

Espero que esteja bem. S√≥ queria te lembrar da nossa reuni√£o marcada para amanh√£, √†s 10h. Por favor, me avise se precisar remarcar ou se houver algo espec√≠fico que voc√™ queira discutir.

Atenciosamente,
Emily
"""

french_safe_email = """
Salut John,

J'esp√®re que tu vas bien. Je voulais juste te rappeler notre r√©union pr√©vue demain √† 10 h. N'h√©site pas √† me contacter si tu souhaites la reporter ou si tu as un sujet particulier √† aborder.

Cordialement,
Emily
"""

english_phishing_email = """
Dear User,

We have detected suspicious activity on your account. For your security, we have temporarily limited access. Please verify your information immediately to avoid permanent suspension:

Verify here: https://houstoncompany.com/verify

If you do not verify within 24 hours, your account will be closed.

Sincerely,
Customer Support
Houston Company
"""

portuguese_phishing_email = """
Prezado Usu√°rio,

Detectamos atividade suspeita em sua conta. Para sua seguran√ßa, limitamos temporariamente o acesso. Verifique suas informa√ß√µes imediatamente para evitar a suspens√£o permanente:

Verifique aqui: https://houstoncompany.com/verify

Se voc√™ n√£o verificar em at√© 24 horas, sua conta ser√° encerrada.

Atenciosamente,
Suporte ao Cliente
Houston Company
"""

french_phishing_email = """
Cher utilisateur,

Nous avons d√©tect√© une activit√© suspecte sur votre compte. Pour votre s√©curit√©, nous en limitons temporairement l'acc√®s. Veuillez v√©rifier vos informations imm√©diatement afin d'√©viter une suspension d√©finitive¬†:

V√©rifiez ici¬†: https://houstoncompany.com/verify

Si vous ne v√©rifiez pas vos informations dans les 24¬†heures, votre compte sera ferm√©.

Cordialement,
Service client
Houston Company
"""

print("english_safe_email: ")
predict(english_safe_email)

print("\nportuguese_safe_email: ")
predict(portuguese_safe_email)

print("\nfrench_safe_email: ")
predict(french_safe_email)

print("\nenglish_phishing_email: ")
predict(english_phishing_email)

print("\nportuguese_phishing_email: ")
predict(portuguese_phishing_email)


print("\nfrench_phishing_email: ")
predict(french_phishing_email)

"""### üí¨ Classifica√ß√£o Interativa com Entrada do Usu√°rio

Para tornar o uso do modelo mais interativo, foi adicionado um pequeno trecho que permite ao usu√°rio **digitar qualquer texto** e em **qualquer idioma** para obter instantaneamente a **classifica√ß√£o do e-mail**, com a respectiva probabilidade de pertencimento √† classe.
"""

# Recebe texto do usu√°rio
user_text = input("Digite o texto que deseja classificar: ")

predict(user_text)

"""## üìä Avalia√ß√£o de Resultados

O objetivo desta se√ß√£o √© realizar uma discuss√£o sobre **o resultado final obtido**, verificando a efic√°cia e consist√™ncia da solu√ß√£o implementada.

---

### 1Ô∏è‚É£ Sele√ß√£o das m√©tricas de avalia√ß√£o
- Foram utilizadas m√©tricas cl√°ssicas de classifica√ß√£o, com **√™nfase no Recall da classe positiva (1 = Phishing Email)**, pois **falsos negativos s√£o cr√≠ticos**.  
- Outras m√©tricas consideradas:
  - **Accuracy**: medida geral de acerto.  
  - **F1-score**: equil√≠brio entre precis√£o e recall.  
  - **ROC AUC e PR AUC**: desempenho do modelo considerando diferentes limiares de decis√£o.  
- Justificativa: o problema exige priorizar a **identifica√ß√£o de phishing**, mesmo que isso ocasione alguns falsos positivos.

---

### 2Ô∏è‚É£ Treino do modelo escolhido
- O modelo selecionado foi o **LGBMClassifier**, por apresentar **melhor Recall** e **baixo tempo de execu√ß√£o**.  
---

### 3Ô∏è‚É£ Teste do modelo
- Avaliado em **conjunto de teste do dataset original**, garantindo dados n√£o vistos pelo modelo.  
- Avaliado em **segundo dataset totalmente distinto**, para verificar capacidade de generaliza√ß√£o com emails em contextos possivelmente diferentes.
- Resultados:  
  - O modelo identificou corretamente os emails de phishing com acur√°cia/recall aceit√°veis.

---

### 4Ô∏è‚É£ An√°lise dos resultados
- **Resultados:** a alta taxa de Recall mostra que o modelo √© eficiente em identificar emails de phishing.  
- **Overfitting:** n√£o foi observado overfitting significativo, dado que o modelo manteve desempenho razo√°vel nos conjuntos de teste.
- **Compara√ß√£o entre modelos:** o LGBM se destacou frente a outros algoritmos avaliados pelo `LazyClassifier`, equilibrando **precis√£o, recall e tempo de execu√ß√£o**.

---

### 5Ô∏è‚É£ Melhor solu√ß√£o encontrada
- **Modelo:** LGBMClassifier + TF-IDF  
- **Justificativa:**  
  - **Alta capacidade de identificar phishing** (Recall elevado).  
  - **Baixo custo computacional**, adequado para implementa√ß√£o em ferramentas leves.  
  - **Boa generaliza√ß√£o** para textos em diferentes contextos e idiomas (com tradu√ß√£o para ingl√™s).  
- Essa solu√ß√£o atende ao objetivo do projeto: criar um modelo **leve, eficiente e pr√°tico**, pronto para uso em cen√°rios reais de aux√≠lio ao usu√°rio.

"""